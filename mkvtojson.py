# -*- coding: utf-8 -*-
"""MKVTOJSON

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fGJHZiT0ILr2tpS6_gbWObQx5dVFyd5q
"""

# Commented out IPython magic to ensure Python compatibility.
# ─── FULL PIPELINE CELL ────────────────────────────────────────────────

# 1) Install system + Python deps
!apt-get update -qq && apt-get install -y -qq ffmpeg
!pip install -q huggingface_hub tensorflow scikit-video imutils opencv-python SoccerNet moviepy scikit-learn

# 2) Clone SoccerNet repo
!git clone https://github.com/SoccerNet/sn-spotting.git
# %cd sn-spotting

# 3) Upload your MKV
from google.colab import files
uploaded = files.upload()        # ← pick your .mkv
input_video = list(uploaded.keys())[0]

# 4) Downscale to 224p@2fps, strip audio
!ffmpeg -y -i "{input_video}" -vf scale=-1:224,fps=2 -an temp_224p.mp4

# 5) Prepare dirs
!mkdir -p output pretrained_model

# 6) Extract raw ResNet‑152 features at 1 FPS
import cv2, numpy as np, tensorflow as tf
from tensorflow.keras.applications.resnet import ResNet152, preprocess_input

VIDEO_FILE = "temp_224p.mp4"
FPS        = 1
BATCH      = 64
OUT_RAW    = "output/raw_features.npy"

# Load ResNet
resnet = ResNet152(weights="imagenet", include_top=False, pooling="avg")

# Read & center‑crop frames
cap  = cv2.VideoCapture(VIDEO_FILE)
orig = cap.get(cv2.CAP_PROP_FPS)
step = max(1, int(orig/FPS))
frames=[]
i=0
while True:
    ret,frm = cap.read()
    if not ret: break
    if i%step==0:
        h,w,_=frm.shape
        if h>w:
            frm=frm[(h-w)//2:(h+w)//2,:]
        else:
            frm=frm[:,(w-h)//2:(w+h)//2]
        frm=cv2.resize(frm,(224,224))[:,:,::-1]
        frames.append(frm)
    i+=1
cap.release()

X = preprocess_input(np.array(frames,dtype=np.float32))
feats=[]
for s in range(0,len(X),BATCH):
    feats.append(resnet.predict(X[s:s+BATCH],verbose=0))
feats = np.vstack(feats)
np.save(OUT_RAW,feats)
print("✅ Raw features:", feats.shape, "→", OUT_RAW)

# 7) Download the HuggingFace model & normalizer (include variables!)
from huggingface_hub import snapshot_download
import os, shutil, pickle

REPO   = "yahoo-inc/spivak-action-spotting-soccernet"
MDIR   = (
  "spotting_challenge_validated_resnet_normalized_confidence_"
  "zoo_lr5e-4_dwd2e-4_sr0.02_mu0.0"
)
# fetch entire model folder + normalizer
ALLOW = [
  f"models/{MDIR}/**",
  "models/resnet_normalizer.pkl",
]
snapshot_download(repo_id=REPO, local_dir="pretrained_model", allow_patterns=ALLOW)

# move variable shards into a 'variables' subdir
best = os.path.join("pretrained_model","models",MDIR,"best_model")
var  = os.path.join(best,"variables")
os.makedirs(var, exist_ok=True)
for fn in os.listdir(best):
    if fn.startswith("variables.") and fn.endswith(("index","of-00001")):
        shutil.move(os.path.join(best,fn), os.path.join(var,fn))

# load normalizer + SavedModel
norm_p = os.path.join("pretrained_model","models","resnet_normalizer.pkl")
with open(norm_p,"rb") as f: scaler = pickle.load(f)
sm = tf.saved_model.load(best)
infer = sm.signatures["serving_default"]
print("✅ Loaded model + normalizer")

# 8) Sliding‑window inference
feats = np.load(OUT_RAW)
T,F   = feats.shape
W     = 224
half  = W//2
pad   = np.pad(feats, ((half,half),(0,0)), mode="edge")

in_key  = list(infer.structured_input_signature[1].keys())[0]
out_key = list(infer.structured_outputs.keys())[0]

batch_w = 16
preds_c = []

for st in range(0, T, batch_w):
    en = min(st+batch_w, T)
    B  = en-st
    batch = np.zeros((B,W,F,1),dtype=np.float32)
    for i,t in enumerate(range(st,en)):
        batch[i,:,:,0] = pad[t:t+W]
    flat = batch[...,0].reshape(-1,F)
    flatn= scaler.transform(flat)
    batch[...,0] = flatn.reshape(B,W,F)
    out  = infer(**{in_key:tf.constant(batch)})
    log  = out[out_key].numpy()[...,0]
    preds_c.append(log[:,half,:])

predictions = np.vstack(preds_c)
print("✅ predictions shape:", predictions.shape)

# 9) Peak‑pick & write JSON
import json
labels = [
  "Penalty","Kick-off","Goal","Substitution","Offside",
  "Shot on target","Shot off target","Clearance","Ball out of play",
  "Throw-in","Foul","Indirect free-kick","Direct free-kick","Corner",
  "Yellow card","Red card","Yellow->red card"
]
TH,WIN = 0.5,5
events=[]
for ci,lab in enumerate(labels):
    sc=predictions[:,ci]
    for t,s in enumerate(sc):
        if s<TH: continue
        lo,hi = max(0,t-WIN), min(T,t+WIN+1)
        if s>=sc[lo:hi].max():
            sec  = float(t)
            halfp=1 if sec<45*60 else 2
            rel  = sec if halfp==1 else sec-45*60
            m,s2=divmod(int(rel),60)
            events.append({
              "label":lab,
              "half":halfp,
              "gameTime":f"{halfp} - {m:02d}:{s2:02d}",
              "timestamp":round(sec,1)
            })
print(f"✅ Spotted {len(events)} events.")

out_f = "output/events.json"
with open(out_f,"w") as f:
    json.dump({"events":events},f,indent=2)
print("✅ Saved JSON →", out_f)

# 10) Download the JSON
files.download(out_f)